{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Notebook\n",
    "The notebook conatains the code for building the Machine Learning model for Flair Prediction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn import decomposition, ensemble\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the data using pandas csv method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df = pd.read_csv('reddit_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the top 5 rows of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>score</th>\n",
       "      <th>id</th>\n",
       "      <th>url</th>\n",
       "      <th>comms_num</th>\n",
       "      <th>created</th>\n",
       "      <th>body</th>\n",
       "      <th>author</th>\n",
       "      <th>flair</th>\n",
       "      <th>comment</th>\n",
       "      <th>authors</th>\n",
       "      <th>feature_combine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>men 30+ decided get married plan old age</td>\n",
       "      <td>257</td>\n",
       "      <td>fvy95j</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fvy95j...</td>\n",
       "      <td>206</td>\n",
       "      <td>1.586207e+09</td>\n",
       "      <td>corona virus given time think life choices bit...</td>\n",
       "      <td>indianoogler</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>plan finances work enjoy ways healthy go see w...</td>\n",
       "      <td>RedDevil-84 congratsindia khushraho kingof-po...</td>\n",
       "      <td>men 30+ decided get married plan old ageplan f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>plan 5th april 9pm switch lights play bella ci...</td>\n",
       "      <td>125</td>\n",
       "      <td>fv8lt3</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fv8lt3...</td>\n",
       "      <td>82</td>\n",
       "      <td>1.586093e+09</td>\n",
       "      <td>dont like worship leaders without logic sympat...</td>\n",
       "      <td>ioup568</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>made whatsapp forward post anyone interestedpl...</td>\n",
       "      <td>AnonymousSeeker5 TablePrime69 faceofnobody no...</td>\n",
       "      <td>plan 5th april 9pm switch lights play bella ci...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>got scammed today foolishness give advice im r...</td>\n",
       "      <td>217</td>\n",
       "      <td>ftjihj</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/ftjihj...</td>\n",
       "      <td>75</td>\n",
       "      <td>1.585849e+09</td>\n",
       "      <td>info meim 12th class recently registered googl...</td>\n",
       "      <td>Momos-</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>literally every message every bank says share ...</td>\n",
       "      <td>saadakhtar SerpantSociety BombayCynic iphone4...</td>\n",
       "      <td>got scammed today foolishness give advice im r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>serious friends doctor husband become paranoid...</td>\n",
       "      <td>149</td>\n",
       "      <td>fu3f8b</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fu3f8b...</td>\n",
       "      <td>76</td>\n",
       "      <td>1.585925e+09</td>\n",
       "      <td>doctor says 100 sure virus spreading via veget...</td>\n",
       "      <td>wordswithmagic</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>1 research study 2013 https linkspringercom ar...</td>\n",
       "      <td>Neglectedsince1994 captainobvioushuman adga49...</td>\n",
       "      <td>serious friends doctor husband become paranoid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>employer making come office even subtle pressu...</td>\n",
       "      <td>308</td>\n",
       "      <td>fjx0dq</td>\n",
       "      <td>https://www.reddit.com/r/india/comments/fjx0dq...</td>\n",
       "      <td>113</td>\n",
       "      <td>1.584439e+09</td>\n",
       "      <td>fill form 100 anonymous take less minute https...</td>\n",
       "      <td>pensker</td>\n",
       "      <td>AskIndia</td>\n",
       "      <td>good luck employer act one two people die lol ...</td>\n",
       "      <td>ekkanpuriya Death_Pig nuvo_reddit goldyprag s...</td>\n",
       "      <td>employer making come office even subtle pressu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  score      id  \\\n",
       "0           men 30+ decided get married plan old age    257  fvy95j   \n",
       "1  plan 5th april 9pm switch lights play bella ci...    125  fv8lt3   \n",
       "2  got scammed today foolishness give advice im r...    217  ftjihj   \n",
       "3  serious friends doctor husband become paranoid...    149  fu3f8b   \n",
       "4  employer making come office even subtle pressu...    308  fjx0dq   \n",
       "\n",
       "                                                 url  comms_num       created  \\\n",
       "0  https://www.reddit.com/r/india/comments/fvy95j...        206  1.586207e+09   \n",
       "1  https://www.reddit.com/r/india/comments/fv8lt3...         82  1.586093e+09   \n",
       "2  https://www.reddit.com/r/india/comments/ftjihj...         75  1.585849e+09   \n",
       "3  https://www.reddit.com/r/india/comments/fu3f8b...         76  1.585925e+09   \n",
       "4  https://www.reddit.com/r/india/comments/fjx0dq...        113  1.584439e+09   \n",
       "\n",
       "                                                body          author  \\\n",
       "0  corona virus given time think life choices bit...    indianoogler   \n",
       "1  dont like worship leaders without logic sympat...         ioup568   \n",
       "2  info meim 12th class recently registered googl...          Momos-   \n",
       "3  doctor says 100 sure virus spreading via veget...  wordswithmagic   \n",
       "4  fill form 100 anonymous take less minute https...         pensker   \n",
       "\n",
       "      flair                                            comment  \\\n",
       "0  AskIndia  plan finances work enjoy ways healthy go see w...   \n",
       "1  AskIndia  made whatsapp forward post anyone interestedpl...   \n",
       "2  AskIndia  literally every message every bank says share ...   \n",
       "3  AskIndia  1 research study 2013 https linkspringercom ar...   \n",
       "4  AskIndia  good luck employer act one two people die lol ...   \n",
       "\n",
       "                                             authors  \\\n",
       "0   RedDevil-84 congratsindia khushraho kingof-po...   \n",
       "1   AnonymousSeeker5 TablePrime69 faceofnobody no...   \n",
       "2   saadakhtar SerpantSociety BombayCynic iphone4...   \n",
       "3   Neglectedsince1994 captainobvioushuman adga49...   \n",
       "4   ekkanpuriya Death_Pig nuvo_reddit goldyprag s...   \n",
       "\n",
       "                                     feature_combine  \n",
       "0  men 30+ decided get married plan old ageplan f...  \n",
       "1  plan 5th april 9pm switch lights play bella ci...  \n",
       "2  got scammed today foolishness give advice im r...  \n",
       "3  serious friends doctor husband become paranoid...  \n",
       "4  employer making come office even subtle pressu...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Python List of the flair tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "flair_tags = [\"AskIndia\", \"Unverified\", \"Non-Political\", \n",
    "          \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
    "          \"Politics\", \"Business/Finance\", \"Policy/Economy\",\n",
    "          \"Sports\", \"Food\", \"[R]eddiquette\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replacing all the null values with \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.fillna(\"\",inplace = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Trying out different models using different features of the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive Bayes Classifier\n",
    "I have used the naive bayes classifier as the first model. I have defined the pipeline as the data is text so using the Pipeline method I have converted the data using Count Vectorizer and TF-IDF transform as to trained different features on the classifier.<br>\n",
    "I have used the follwing features to train the model\n",
    "1. Title\n",
    "2. URL\n",
    "3. Body\n",
    "4. Comment\n",
    "5. Feature Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_bayes_classifier(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    nb_classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                              ('tfidf', TfidfTransformer()),\n",
    "                              ('clf', MultinomialNB()),\n",
    "                             ])\n",
    "    nb_classifier.fit(X_train, y_train)\n",
    "    y_pred = nb_classifier.predict(X_val)\n",
    "    \n",
    "    print('accuracy %s' % metrics.accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=flair_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.41106719367588934\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.34      1.00      0.50       148\n",
      "        Unverified       0.75      0.11      0.19        28\n",
      "     Non-Political       0.00      0.00      0.00        33\n",
      "         Scheduled       1.00      0.17      0.29        54\n",
      "       Photography       1.00      0.23      0.38        30\n",
      "Science/Technology       0.00      0.00      0.00        37\n",
      "          Politics       1.00      0.04      0.07        28\n",
      "  Business/Finance       0.90      0.97      0.94        39\n",
      "    Policy/Economy       0.00      0.00      0.00        30\n",
      "            Sports       1.00      0.03      0.07        29\n",
      "              Food       1.00      0.04      0.07        26\n",
      "     [R]eddiquette       0.00      0.00      0.00        24\n",
      "\n",
      "          accuracy                           0.41       506\n",
      "         macro avg       0.58      0.22      0.21       506\n",
      "      weighted avg       0.54      0.41      0.29       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "naive_bayes_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4624505928853755\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.46      1.00      0.63       148\n",
      "        Unverified       0.48      0.39      0.43        28\n",
      "     Non-Political       0.00      0.00      0.00        33\n",
      "         Scheduled       0.44      0.44      0.44        54\n",
      "       Photography       0.38      0.90      0.53        30\n",
      "Science/Technology       0.50      0.05      0.10        37\n",
      "          Politics       0.33      0.04      0.06        28\n",
      "  Business/Finance       1.00      0.05      0.10        39\n",
      "    Policy/Economy       1.00      0.13      0.24        30\n",
      "            Sports       0.79      0.52      0.62        29\n",
      "              Food       0.00      0.00      0.00        26\n",
      "     [R]eddiquette       0.00      0.00      0.00        24\n",
      "\n",
      "          accuracy                           0.46       506\n",
      "         macro avg       0.45      0.29      0.26       506\n",
      "      weighted avg       0.47      0.46      0.35       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "naive_bayes_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3695652173913043\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.32      1.00      0.48       148\n",
      "        Unverified       0.00      0.00      0.00        28\n",
      "     Non-Political       0.00      0.00      0.00        33\n",
      "         Scheduled       0.00      0.00      0.00        54\n",
      "       Photography       0.00      0.00      0.00        30\n",
      "Science/Technology       0.00      0.00      0.00        37\n",
      "          Politics       0.00      0.00      0.00        28\n",
      "  Business/Finance       0.95      0.97      0.96        39\n",
      "    Policy/Economy       0.00      0.00      0.00        30\n",
      "            Sports       0.00      0.00      0.00        29\n",
      "              Food       0.00      0.00      0.00        26\n",
      "     [R]eddiquette       1.00      0.04      0.08        24\n",
      "\n",
      "          accuracy                           0.37       506\n",
      "         macro avg       0.19      0.17      0.13       506\n",
      "      weighted avg       0.21      0.37      0.22       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.body\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "naive_bayes_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3142292490118577\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.30      1.00      0.46       148\n",
      "        Unverified       0.00      0.00      0.00        28\n",
      "     Non-Political       0.00      0.00      0.00        33\n",
      "         Scheduled       0.00      0.00      0.00        54\n",
      "       Photography       1.00      0.03      0.06        30\n",
      "Science/Technology       0.00      0.00      0.00        37\n",
      "          Politics       0.00      0.00      0.00        28\n",
      "  Business/Finance       0.91      0.26      0.40        39\n",
      "    Policy/Economy       0.00      0.00      0.00        30\n",
      "            Sports       0.00      0.00      0.00        29\n",
      "              Food       0.00      0.00      0.00        26\n",
      "     [R]eddiquette       0.00      0.00      0.00        24\n",
      "\n",
      "          accuracy                           0.31       506\n",
      "         macro avg       0.18      0.11      0.08       506\n",
      "      weighted avg       0.22      0.31      0.17       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.comment\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "naive_bayes_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.3201581027667984\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.30      1.00      0.46       148\n",
      "        Unverified       0.00      0.00      0.00        28\n",
      "     Non-Political       0.00      0.00      0.00        33\n",
      "         Scheduled       0.00      0.00      0.00        54\n",
      "       Photography       1.00      0.03      0.06        30\n",
      "Science/Technology       0.00      0.00      0.00        37\n",
      "          Politics       0.00      0.00      0.00        28\n",
      "  Business/Finance       1.00      0.33      0.50        39\n",
      "    Policy/Economy       0.00      0.00      0.00        30\n",
      "            Sports       0.00      0.00      0.00        29\n",
      "              Food       0.00      0.00      0.00        26\n",
      "     [R]eddiquette       0.00      0.00      0.00        24\n",
      "\n",
      "          accuracy                           0.32       506\n",
      "         macro avg       0.19      0.11      0.09       506\n",
      "      weighted avg       0.22      0.32      0.18       506\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state=42)\n",
    "naive_bayes_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Classifier\n",
    "I have used the Logistic Regression Classifier as the second model. I have defined the pipeline as the data is text so using the Pipeline method. I have converted the data using Count Vectorizer and TF-IDF transform as to trained different features on the classifier. I have used different values of C and the maximum iteration but got the best accuracy at C = 1e6 and maximum iteration 200.<br>\n",
    "I have used the follwing features to train the model\n",
    "1. Title\n",
    "2. URL\n",
    "3. Body\n",
    "4. Comment\n",
    "5. Feature Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logisticreg_classifier(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    logreg_classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                                  ('tfidf', TfidfTransformer()),\n",
    "                                  ('clf', LogisticRegression(n_jobs=1, max_iter = 200, C=1e6))\n",
    "                                 ])\n",
    "    logreg_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg_classifier.predict(X_val)\n",
    "\n",
    "    print('accuracy %s' % metrics.accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=flair_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6798418972332015\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.72      1.00      0.84        65\n",
      "        Unverified       0.50      0.60      0.55        15\n",
      "     Non-Political       0.33      0.40      0.36        15\n",
      "         Scheduled       0.76      0.85      0.80        26\n",
      "       Photography       0.67      0.71      0.69        14\n",
      "Science/Technology       0.50      0.11      0.18        18\n",
      "          Politics       0.55      0.35      0.43        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.67      0.50      0.57        16\n",
      "            Sports       0.82      0.78      0.80        18\n",
      "              Food       0.50      0.28      0.36        18\n",
      "     [R]eddiquette       0.62      0.45      0.53        11\n",
      "\n",
      "          accuracy                           0.68       253\n",
      "         macro avg       0.63      0.59      0.59       253\n",
      "      weighted avg       0.66      0.68      0.65       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "logisticreg_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5691699604743083\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      1.00      0.75        65\n",
      "        Unverified       0.43      0.40      0.41        15\n",
      "     Non-Political       0.00      0.00      0.00        15\n",
      "         Scheduled       0.92      0.85      0.88        26\n",
      "       Photography       0.32      1.00      0.48        14\n",
      "Science/Technology       0.18      0.11      0.14        18\n",
      "          Politics       0.50      0.12      0.19        17\n",
      "  Business/Finance       0.94      0.75      0.83        20\n",
      "    Policy/Economy       0.30      0.19      0.23        16\n",
      "            Sports       0.71      0.67      0.69        18\n",
      "              Food       0.00      0.00      0.00        18\n",
      "     [R]eddiquette       0.75      0.27      0.40        11\n",
      "\n",
      "          accuracy                           0.57       253\n",
      "         macro avg       0.47      0.45      0.42       253\n",
      "      weighted avg       0.51      0.57      0.50       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "logisticreg_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6679841897233202\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.83      0.97      0.89        65\n",
      "        Unverified       0.62      0.53      0.57        15\n",
      "     Non-Political       0.62      0.53      0.57        15\n",
      "         Scheduled       0.70      0.81      0.75        26\n",
      "       Photography       0.89      0.57      0.70        14\n",
      "Science/Technology       0.33      0.22      0.27        18\n",
      "          Politics       0.57      0.47      0.52        17\n",
      "  Business/Finance       0.87      1.00      0.93        20\n",
      "    Policy/Economy       1.00      0.19      0.32        16\n",
      "            Sports       0.59      0.72      0.65        18\n",
      "              Food       0.38      0.50      0.43        18\n",
      "     [R]eddiquette       0.29      0.36      0.32        11\n",
      "\n",
      "          accuracy                           0.67       253\n",
      "         macro avg       0.64      0.57      0.58       253\n",
      "      weighted avg       0.68      0.67      0.65       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.comment\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "logisticreg_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.48221343873517786\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.85      0.94      0.89        65\n",
      "        Unverified       1.00      0.07      0.12        15\n",
      "     Non-Political       0.83      0.33      0.48        15\n",
      "         Scheduled       0.20      1.00      0.33        26\n",
      "       Photography       0.00      0.00      0.00        14\n",
      "Science/Technology       0.62      0.28      0.38        18\n",
      "          Politics       1.00      0.06      0.11        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.00      0.00      0.00        16\n",
      "            Sports       0.00      0.00      0.00        18\n",
      "              Food       0.14      0.06      0.08        18\n",
      "     [R]eddiquette       0.50      0.18      0.27        11\n",
      "\n",
      "          accuracy                           0.48       253\n",
      "         macro avg       0.51      0.33      0.30       253\n",
      "      weighted avg       0.57      0.48      0.43       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.body\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "logisticreg_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7272727272727273\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.79      0.97      0.87        65\n",
      "        Unverified       0.53      0.53      0.53        15\n",
      "     Non-Political       0.69      0.60      0.64        15\n",
      "         Scheduled       0.75      0.81      0.78        26\n",
      "       Photography       0.80      0.86      0.83        14\n",
      "Science/Technology       0.36      0.28      0.31        18\n",
      "          Politics       0.64      0.53      0.58        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.70      0.44      0.54        16\n",
      "            Sports       0.95      1.00      0.97        18\n",
      "              Food       0.54      0.39      0.45        18\n",
      "     [R]eddiquette       0.45      0.45      0.45        11\n",
      "\n",
      "          accuracy                           0.73       253\n",
      "         macro avg       0.68      0.65      0.66       253\n",
      "      weighted avg       0.71      0.73      0.71       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "logisticreg_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic SVM (Support Vector Machine) Classifier\n",
    "I have used the SVM as the third model. I have defined the pipeline as the data is text so using the Pipeline method. I have converted the data using Count Vectorizer and TF-IDF transform as to trained different features on the classifier. I have tried to train the model by changing the loss function and the alpha value. Got the best accuracy at the defined values in the function. <br>\n",
    "I have used the follwing features to train the model\n",
    "1. Title\n",
    "2. URL\n",
    "3. Body\n",
    "4. Comment\n",
    "5. Feature Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_svm_classifier(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    sgd_classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                               ('tfidf', TfidfTransformer()),\n",
    "                               ('clf', linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-5, random_state=42, max_iter=100, tol=None)),\n",
    "                              ])\n",
    "    sgd_classifier.fit(X_train, y_train)\n",
    "    y_pred = sgd_classifier.predict(X_val)\n",
    "    \n",
    "    print('accuracy %s' % metrics.accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=flair_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6482213438735178\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.76      1.00      0.86        65\n",
      "        Unverified       0.35      0.40      0.38        15\n",
      "     Non-Political       0.50      0.40      0.44        15\n",
      "         Scheduled       0.63      0.85      0.72        26\n",
      "       Photography       0.67      0.71      0.69        14\n",
      "Science/Technology       0.30      0.17      0.21        18\n",
      "          Politics       0.62      0.29      0.40        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.55      0.38      0.44        16\n",
      "            Sports       0.64      0.78      0.70        18\n",
      "              Food       0.31      0.22      0.26        18\n",
      "     [R]eddiquette       1.00      0.27      0.43        11\n",
      "\n",
      "          accuracy                           0.65       253\n",
      "         macro avg       0.61      0.54      0.54       253\n",
      "      weighted avg       0.63      0.65      0.62       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "linear_svm_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5652173913043478\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.60      1.00      0.75        65\n",
      "        Unverified       0.40      0.40      0.40        15\n",
      "     Non-Political       0.00      0.00      0.00        15\n",
      "         Scheduled       0.85      0.85      0.85        26\n",
      "       Photography       0.32      0.93      0.47        14\n",
      "Science/Technology       0.18      0.11      0.14        18\n",
      "          Politics       0.33      0.06      0.10        17\n",
      "  Business/Finance       0.94      0.75      0.83        20\n",
      "    Policy/Economy       0.43      0.19      0.26        16\n",
      "            Sports       0.71      0.67      0.69        18\n",
      "              Food       0.25      0.06      0.09        18\n",
      "     [R]eddiquette       0.60      0.27      0.37        11\n",
      "\n",
      "          accuracy                           0.57       253\n",
      "         macro avg       0.47      0.44      0.41       253\n",
      "      weighted avg       0.51      0.57      0.50       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "linear_svm_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6521739130434783\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.74      0.97      0.84        65\n",
      "        Unverified       0.36      0.27      0.31        15\n",
      "     Non-Political       0.69      0.60      0.64        15\n",
      "         Scheduled       0.81      0.81      0.81        26\n",
      "       Photography       0.75      0.64      0.69        14\n",
      "Science/Technology       0.26      0.28      0.27        18\n",
      "          Politics       0.56      0.53      0.55        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       1.00      0.19      0.32        16\n",
      "            Sports       0.64      0.89      0.74        18\n",
      "              Food       0.22      0.11      0.15        18\n",
      "     [R]eddiquette       0.31      0.36      0.33        11\n",
      "\n",
      "          accuracy                           0.65       253\n",
      "         macro avg       0.61      0.55      0.55       253\n",
      "      weighted avg       0.65      0.65      0.62       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.comment\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "linear_svm_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4743083003952569\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.82      0.94      0.88        65\n",
      "        Unverified       0.50      0.07      0.12        15\n",
      "     Non-Political       0.83      0.33      0.48        15\n",
      "         Scheduled       1.00      0.19      0.32        26\n",
      "       Photography       0.00      0.00      0.00        14\n",
      "Science/Technology       0.80      0.22      0.35        18\n",
      "          Politics       1.00      0.06      0.11        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.00      0.00      0.00        16\n",
      "            Sports       0.14      1.00      0.25        18\n",
      "              Food       0.33      0.17      0.22        18\n",
      "     [R]eddiquette       0.40      0.18      0.25        11\n",
      "\n",
      "          accuracy                           0.47       253\n",
      "         macro avg       0.57      0.35      0.33       253\n",
      "      weighted avg       0.64      0.47      0.45       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.body\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "linear_svm_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7312252964426877\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.83      0.97      0.89        65\n",
      "        Unverified       0.53      0.60      0.56        15\n",
      "     Non-Political       0.69      0.60      0.64        15\n",
      "         Scheduled       0.73      0.85      0.79        26\n",
      "       Photography       0.71      0.86      0.77        14\n",
      "Science/Technology       0.43      0.33      0.38        18\n",
      "          Politics       0.67      0.47      0.55        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.67      0.38      0.48        16\n",
      "            Sports       0.90      1.00      0.95        18\n",
      "              Food       0.53      0.44      0.48        18\n",
      "     [R]eddiquette       0.44      0.36      0.40        11\n",
      "\n",
      "          accuracy                           0.73       253\n",
      "         macro avg       0.67      0.65      0.66       253\n",
      "      weighted avg       0.71      0.73      0.72       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "linear_svm_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier\n",
    "I have used the Random Forest Classifier as the fourth model. I have defined the pipeline as the data is text so using the Pipeline method. I have converted the data using Count Vectorizer and TF-IDF transform as to trained different features on the classifier. <br>\n",
    "I have used the follwing features to train the model\n",
    "1. Title\n",
    "2. URL\n",
    "3. Body\n",
    "4. Comment\n",
    "5. Feature Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomforest_classifier(X_train, X_val, y_train, y_val):\n",
    "    \n",
    "    randomforest_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', ensemble.RandomForestClassifier(n_estimators = 1000, random_state = 42)),\n",
    "                 ])\n",
    "    randomforest_clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = randomforest_clf.predict(X_val)\n",
    "    \n",
    "    print('accuracy %s' % metrics.accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=flair_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6086956521739131\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.61      0.97      0.75        65\n",
      "        Unverified       0.43      0.40      0.41        15\n",
      "     Non-Political       0.71      0.33      0.45        15\n",
      "         Scheduled       0.49      0.88      0.63        26\n",
      "       Photography       0.62      0.71      0.67        14\n",
      "Science/Technology       0.80      0.22      0.35        18\n",
      "          Politics       0.50      0.18      0.26        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.56      0.31      0.40        16\n",
      "            Sports       1.00      0.61      0.76        18\n",
      "              Food       0.43      0.17      0.24        18\n",
      "     [R]eddiquette       0.14      0.09      0.11        11\n",
      "\n",
      "          accuracy                           0.61       253\n",
      "         macro avg       0.60      0.49      0.50       253\n",
      "      weighted avg       0.62      0.61      0.57       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "randomforest_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5296442687747036\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.70      0.97      0.81        65\n",
      "        Unverified       0.42      0.33      0.37        15\n",
      "     Non-Political       0.00      0.00      0.00        15\n",
      "         Scheduled       0.49      0.85      0.62        26\n",
      "       Photography       0.00      0.00      0.00        14\n",
      "Science/Technology       0.20      0.06      0.09        18\n",
      "          Politics       0.00      0.00      0.00        17\n",
      "  Business/Finance       0.33      1.00      0.49        20\n",
      "    Policy/Economy       0.44      0.44      0.44        16\n",
      "            Sports       0.74      0.78      0.76        18\n",
      "              Food       0.00      0.00      0.00        18\n",
      "     [R]eddiquette       1.00      0.18      0.31        11\n",
      "\n",
      "          accuracy                           0.53       253\n",
      "         macro avg       0.36      0.38      0.32       253\n",
      "      weighted avg       0.42      0.53      0.43       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "randomforest_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5177865612648221\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.43      1.00      0.60        65\n",
      "        Unverified       0.71      0.33      0.45        15\n",
      "     Non-Political       0.75      0.20      0.32        15\n",
      "         Scheduled       1.00      0.58      0.73        26\n",
      "       Photography       0.62      0.36      0.45        14\n",
      "Science/Technology       1.00      0.06      0.11        18\n",
      "          Politics       1.00      0.06      0.11        17\n",
      "  Business/Finance       0.87      1.00      0.93        20\n",
      "    Policy/Economy       0.67      0.12      0.21        16\n",
      "            Sports       0.32      0.67      0.44        18\n",
      "              Food       1.00      0.06      0.11        18\n",
      "     [R]eddiquette       1.00      0.09      0.17        11\n",
      "\n",
      "          accuracy                           0.52       253\n",
      "         macro avg       0.78      0.38      0.39       253\n",
      "      weighted avg       0.72      0.52      0.45       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.comment\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "randomforest_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.43478260869565216\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.64      0.97      0.77        65\n",
      "        Unverified       0.00      0.00      0.00        15\n",
      "     Non-Political       0.00      0.00      0.00        15\n",
      "         Scheduled       0.19      0.96      0.32        26\n",
      "       Photography       0.00      0.00      0.00        14\n",
      "Science/Technology       1.00      0.06      0.11        18\n",
      "          Politics       0.00      0.00      0.00        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.00      0.00      0.00        16\n",
      "            Sports       0.00      0.00      0.00        18\n",
      "              Food       0.00      0.00      0.00        18\n",
      "     [R]eddiquette       0.50      0.09      0.15        11\n",
      "\n",
      "          accuracy                           0.43       253\n",
      "         macro avg       0.27      0.26      0.19       253\n",
      "      weighted avg       0.35      0.43      0.32       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.body\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "randomforest_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5849802371541502\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.51      1.00      0.67        65\n",
      "        Unverified       0.50      0.33      0.40        15\n",
      "     Non-Political       0.40      0.13      0.20        15\n",
      "         Scheduled       0.86      0.69      0.77        26\n",
      "       Photography       0.46      0.93      0.62        14\n",
      "Science/Technology       0.33      0.06      0.10        18\n",
      "          Politics       1.00      0.24      0.38        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       1.00      0.25      0.40        16\n",
      "            Sports       0.56      0.83      0.67        18\n",
      "              Food       0.00      0.00      0.00        18\n",
      "     [R]eddiquette       0.50      0.09      0.15        11\n",
      "\n",
      "          accuracy                           0.58       253\n",
      "         macro avg       0.59      0.46      0.44       253\n",
      "      weighted avg       0.59      0.58      0.51       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "randomforest_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLP Classifier\n",
    "I have used the MLP Classifier as the fifth model. I have defined the pipeline as the data is text so using the Pipeline method. I have converted the data using Count Vectorizer and TF-IDF transform as to trained different features on the classifier. I have tried to train the model using different hidden layers and the activation function. <br>\n",
    "I have used the follwing features to train the model\n",
    "1. Title\n",
    "2. URL\n",
    "3. Body\n",
    "4. Comment\n",
    "5. Feature Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "def mlp_classifier(X_train, X_val, y_train, y_val):  \n",
    "    mlp_classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                  ('tfidf', TfidfTransformer()),\n",
    "                  ('clf', MLPClassifier(hidden_layer_sizes=(30,40,30), activation=\"relu\", max_iter = 200 )),\n",
    "                 ])\n",
    "    \n",
    "    mlp_classifier.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred = mlp_classifier.predict(X_val)\n",
    "    \n",
    "    print('accuracy %s' % metrics.accuracy_score(y_pred, y_val))\n",
    "    print(classification_report(y_val, y_pred,target_names=flair_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6442687747035574\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.80      1.00      0.89        65\n",
      "        Unverified       0.39      0.47      0.42        15\n",
      "     Non-Political       0.43      0.60      0.50        15\n",
      "         Scheduled       0.81      0.85      0.83        26\n",
      "       Photography       0.75      0.64      0.69        14\n",
      "Science/Technology       0.33      0.28      0.30        18\n",
      "          Politics       0.43      0.18      0.25        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.47      0.44      0.45        16\n",
      "            Sports       0.83      0.56      0.67        18\n",
      "              Food       0.18      0.17      0.17        18\n",
      "     [R]eddiquette       0.43      0.27      0.33        11\n",
      "\n",
      "          accuracy                           0.64       253\n",
      "         macro avg       0.57      0.54      0.54       253\n",
      "      weighted avg       0.63      0.64      0.63       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.title\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "mlp_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5612648221343873\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       1.00      0.97      0.98        65\n",
      "        Unverified       0.43      0.40      0.41        15\n",
      "     Non-Political       0.00      0.00      0.00        15\n",
      "         Scheduled       0.91      0.81      0.86        26\n",
      "       Photography       0.30      0.93      0.46        14\n",
      "Science/Technology       0.27      0.17      0.21        18\n",
      "          Politics       0.33      0.18      0.23        17\n",
      "  Business/Finance       0.94      0.75      0.83        20\n",
      "    Policy/Economy       1.00      0.06      0.12        16\n",
      "            Sports       0.75      0.67      0.71        18\n",
      "              Food       0.00      0.00      0.00        18\n",
      "     [R]eddiquette       0.10      0.45      0.17        11\n",
      "\n",
      "          accuracy                           0.56       253\n",
      "         macro avg       0.50      0.45      0.41       253\n",
      "      weighted avg       0.63      0.56      0.55       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.url\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "mlp_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6086956521739131\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.80      0.97      0.88        65\n",
      "        Unverified       0.29      0.13      0.18        15\n",
      "     Non-Political       0.56      0.60      0.58        15\n",
      "         Scheduled       0.88      0.81      0.84        26\n",
      "       Photography       0.50      0.57      0.53        14\n",
      "Science/Technology       0.44      0.39      0.41        18\n",
      "          Politics       0.56      0.53      0.55        17\n",
      "  Business/Finance       1.00      0.65      0.79        20\n",
      "    Policy/Economy       0.67      0.12      0.21        16\n",
      "            Sports       0.50      0.61      0.55        18\n",
      "              Food       0.18      0.39      0.25        18\n",
      "     [R]eddiquette       0.67      0.18      0.29        11\n",
      "\n",
      "          accuracy                           0.61       253\n",
      "         macro avg       0.59      0.50      0.50       253\n",
      "      weighted avg       0.64      0.61      0.60       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.comment\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "mlp_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.4782608695652174\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.92      0.94      0.93        65\n",
      "        Unverified       0.00      0.00      0.00        15\n",
      "     Non-Political       0.67      0.40      0.50        15\n",
      "         Scheduled       0.19      0.96      0.31        26\n",
      "       Photography       0.00      0.00      0.00        14\n",
      "Science/Technology       0.50      0.17      0.25        18\n",
      "          Politics       0.33      0.06      0.10        17\n",
      "  Business/Finance       0.95      1.00      0.98        20\n",
      "    Policy/Economy       0.00      0.00      0.00        16\n",
      "            Sports       0.00      0.00      0.00        18\n",
      "              Food       0.44      0.22      0.30        18\n",
      "     [R]eddiquette       1.00      0.09      0.17        11\n",
      "\n",
      "          accuracy                           0.48       253\n",
      "         macro avg       0.42      0.32      0.29       253\n",
      "      weighted avg       0.50      0.48      0.43       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.body\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "mlp_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6482213438735178\n",
      "                    precision    recall  f1-score   support\n",
      "\n",
      "          AskIndia       0.97      0.97      0.97        65\n",
      "        Unverified       0.38      0.33      0.36        15\n",
      "     Non-Political       0.53      0.60      0.56        15\n",
      "         Scheduled       0.95      0.81      0.88        26\n",
      "       Photography       0.83      0.71      0.77        14\n",
      "Science/Technology       0.24      0.50      0.33        18\n",
      "          Politics       1.00      0.06      0.11        17\n",
      "  Business/Finance       0.90      0.95      0.93        20\n",
      "    Policy/Economy       0.33      0.12      0.18        16\n",
      "            Sports       0.45      0.94      0.61        18\n",
      "              Food       0.33      0.11      0.17        18\n",
      "     [R]eddiquette       0.40      0.55      0.46        11\n",
      "\n",
      "          accuracy                           0.65       253\n",
      "         macro avg       0.61      0.55      0.53       253\n",
      "      weighted avg       0.70      0.65      0.63       253\n",
      "\n"
     ]
    }
   ],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)\n",
    "mlp_classifier(X_train, X_val, y_train, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below imports the pickle library and save the best model as pickle object.<br>\n",
    "The best model is the SVM classifier with accuracy of 73.12% on the feature_combine features of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.feature_combine\n",
    "y = df.flair\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_classifier = Pipeline([('vect', CountVectorizer()),\n",
    "                               ('tfidf', TfidfTransformer()),\n",
    "                               ('clf', linear_model.SGDClassifier(loss='hinge', penalty='l2', alpha=1e-5, random_state=42, max_iter=100, tol=None)),\n",
    "                              ])\n",
    "sgd_classifier.fit(X_train, y_train)\n",
    "pickle.dump(sgd_classifier,open(\"sgdClf.pkl\",'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
