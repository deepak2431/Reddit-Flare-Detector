{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reddit Data Scrapper Notebook\n",
    "\n",
    "This notebook contains the code to scrap the data of Reddit India using python PRAW(Python Reddit API Wrapper) Library. I have scrapped the top 150 posts of Reddit India. Total 12 different flairs posts has been scrapped. For each of the posts Title, Score, URL, Body, ID, Authors etc has been scrapped. Also the top 20 comments of each posts has been scrapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from pymongo import MongoClient\n",
    "import praw\n",
    "from praw.models import MoreComments\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "client = MongoClient('mongodb://localhost:27017/')\n",
    "db = client[\"reddit\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit = praw.Reddit(client_id='', \\\n",
    "                     client_secret='', \\\n",
    "                     user_agent='flare_detector', \\\n",
    "                     username='', \\\n",
    "                     password='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit = reddit.subreddit('india')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#List of all the flairs. These will be the keys in classification.\n",
    "flairs = [\"AskIndia\", \"Unverified\", \"Non-Political\", \n",
    "          \"Scheduled\", \"Photography\", \"Science/Technology\",\n",
    "          \"Politics\", \"Business/Finance\", \"Policy/Economy\",\n",
    "          \"Sports\", \"Food\", \"[R]eddiquette\"]\n",
    "\n",
    "\n",
    "for flair in flairs:\n",
    "\n",
    "    #The posts' data is collected by searching by the flair name in the list. Top 150 posts are recorded and stored for analysis.\n",
    "\n",
    "    relevant_subreddits = subreddit.search(f\"flair_name:{flair}\",limit=150)\n",
    "\n",
    "    for submission in relevant_subreddits:\n",
    "        posts = {\n",
    "        \"title\":str(submission.title),\n",
    "        \"score\":str(submission.score),\n",
    "        \"id\":str(submission.id),\n",
    "        \"url\":str(submission.url),\n",
    "        \"comms_num\":str(submission.num_comments),\n",
    "        \"created\":str(submission.created),\n",
    "        \"body\":str(submission.selftext),\n",
    "        \"author\":str(submission.author),\n",
    "        \"flair\":str(flair),\t\n",
    "        }\n",
    "\n",
    "#  Only top twenty comments and their authors are considered for the data. \n",
    "        submission.comments.replace_more(limit=None)\n",
    "        comment = ''\n",
    "        authors = ''\n",
    "        count = 0\n",
    "        for top_level_comment in submission.comments:\n",
    "            comment = comment + ' ' + top_level_comment.body\n",
    "            authors = authors + ' ' + str(top_level_comment.author)\n",
    "            count+=1     \n",
    "            if(count > 20):\n",
    "                break\n",
    "\n",
    "        posts[\"comment\"] = str(comment)\n",
    "        posts[\"authors\"] = str(authors)\n",
    "        result = db.posts.insert_one(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
